# 제2부: 이론적 배경 - 스케일링 법칙과 예측 모델

## 1. 사전훈련 vs RL 훈련의 스케일링 차이

### 사전훈련 스케일링 법칙 (기존 이론)
$$
\text{컴퓨팅}(C) \leftrightarrow \text{손실}(L)
L = D \times C^{-\alpha} \quad \text{(거듭제곱 법칙)}
$$

주요 특징:
- 무한 성능 향상 가정
- 로그-로그 스케일에서 선형 관계
- 컴퓨팅 증가 = 성능 선형 향상

### RL 훈련 스케일링 법칙 (본 연구의 발견)
$$
R_C = R_0 + \frac{A - R_0}{1 + (C_{\text{mid}}/C)^B} \quad \text{(시그모이드 법칙)}
$$

주요 특징:
- 유한 성능 한계(A) 존재
- 수확 체감(saturating returns)
- 초기: 느린 성장 → 중기: 급격한 향상 → 후기: 포화

### 왜 시그모이드 함수인가?
1. **유한 메트릭**: 정확도, 통과율 등은 상한(0-1)이 존재
2. **안정적 피팅**: 파워 법칙보다 노이즈에 강건
3. **실제 관찰**: 대규모 RL 훈련에서 포화 현상 명확히 관찰됨

## 2. 시그모이드 스케일링 모델 상세 분석

### 핵심 수식과 파라미터
$$
R_C - R_0 = (A - R_0) \times \frac{1}{1 + (C_{\text{mid}}/C)^B}
$$

여기서:
- $R_C$: 컴퓨팅 $C$에서의 예상 보상
- $R_0$: 초기 보상 (훈련 시작 시점)
- $A$: 점근 성능 ($0 \leq A \leq 1$)
- $C_{\text{mid}}$: 반값에 도달하는 컴퓨팅 지점
- $B$: 스케일링 지수 ($B > 0$, 클수록 효율적)

### 파라미터별 의미와 영향

#### $A$ (점근 성능, Asymptotic Performance)
- **의미**: 무한 컴퓨팅 시 도달할 수 있는 최종 성능
- **중요성**: 알고리즘의 근본적 한계를 결정
- **영향 요인**: 손실 함수 타입, 모델 아키텍처, 데이터 질

#### $B$ (컴퓨팅 효율, Compute Efficiency)
- **의미**: 컴퓨팅 증가에 따른 성능 향상 속도
- **중요성**: 동일한 성능에 도달하는 데 필요한 컴퓨팅 양
- **영향 요인**: 배치 크기, 정규화 방식, 데이터 커리큘럼

#### $C_{\text{mid}}$ (중간점, Midpoint)
- **의미**: 총 성능 향상의 절반을 달성하는 컴퓨팅 지점
- **중요성**: 초기 훈련 효율의 지표
- **영향 요인**: 최적화 알고리즘, 학습률 스케줄

## 3. 파워 법칙 vs 시그모이드 법칙 비교

| 특징 | 파워 법칙 | 시그모이드 법칙 |
|------|----------|------------|
| **적용 대상** | 사전훈련 | RL 훈련 |
| **성장 패턴** | 무한 선형 | 유한 시그모이드 |
| **피팅 안정성** | 저컴퓨팅에서 불안정 | 전 구간에서 안정 |
| **실제 적합성** | RL 훈련 데이터에 부적합 | RL 훈련 데이터에 적합 |
| **예측 정확도** | 고컴퓨팅에서만 정확 | 저컴퓨팅에서도 정확 |

### 고컴퓨팅 근사에서의 시그모이드 근사
$$
C \gg C_{\text{mid}} \text{일 때:}
$$
R_C \approx R_0 + (A - R_0) \times \left[1 - \frac{C_{\text{mid}}^B}{C^B}\right]
$$
$$
= A - \frac{(A - R_0) \times C_{\text{mid}}^B}{C^B}
$$
$$
= A - \frac{D}{C^B} \quad \text{(여기서 } D = (A - R_0) \times C_{\text{mid}}^B)
$$

## 4. 컴퓨팅 효율성의 경제학적 해석

### 한계 생산성 법칙 (Law of Diminishing Returns)
- **초기**: 컴퓨팅 2배 증가 → 성능 2배 향상
- **중기**: 컴퓨팅 2배 증가 → 성능 1.2배 향상
- **후기**: 컴퓨팅 2배 증가 → 성능 1.05배 향상

### 컴퓨팅 투자 수익(ROI) 최적화
$$
\text{ROI} = \frac{\text{성능 향상}}{\text{컴퓨팅 증가}}
$$

최적 전략:
1. $A$(점근 성능) 최대화: 근본적 한계 상향 조정
2. $B$(효율성) 개선: 동일 성능에 도달하는 컴퓨팅 최소화
3. $C_{\text{mid}}$ 최적화: 초기 훈련 속도 향상

## 5. 실제 데이터로의 모델 피팅 사례

### 피팅 절차
1. **데이터 수집**: 100스텝 간격으로 검증 데이터셋에서 통과율 측정
2. **초기 구간 제외**: 1.5K GPU시간 이전 데이터 제외 (안정성 확보)
3. **그리드 서치**: $A \in [0.450, 0.800]$, $C_{\text{mid}} \in [100, 40000]$
4. **최적화**: 최소 제곱합으로 최적 파라미터 탐색

### 통계적 유의성 확보
- **반복 실험**: 3회 독립적인 ScaleRL 실행으로 분산 측정
- **오차 범위**: $A$ 값의 $\pm 0.02$ 내에서 변동 (통계적 유의성 기준)
- **신뢰도 검증**: 다른 피팅 구간에서의 파라미터 안정성 확인

## 6. 강의 핵심 통찰

### 이론적 기여
1. **RL 특화 스케일링 이론**: 최초의 체계적 프레임워크 제시
2. **예측 가능성 증명**: 작은 규모 실험으로 대규모 성능 예측 가능
3. **자원 배분 최적화**: 컴퓨팅 효율성과 성능 한계의 분리적 분석

### 실무적 함의
1. **컴퓨팅 계획**: 과학적 기반의 컴퓨팅 예측과 계획 수립
2. **알고리즘 선택**: 예측 가능한 성능 향상을 보장하는 알고리즘 선정
3. **성과 측정**: 점근 성능($A$)과 효율성($B$)의 분리적 평가

### 다음 강의로의 연결
> "이론적 기반 위에서 실제 실험 설계와 결과 분석으로 나아갑니다."