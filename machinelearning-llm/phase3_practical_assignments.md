# Phase 3: 트랜스포머 아키텍처와 LLM 기초 - 실습 과제 모음

## 과제 개요

Phase 3의 실습 과제는 LLM의 핵심 기술인 트랜스포머 아키텍처, 사전 훈련, 미세조정 방법론을 깊이 이해하고 직접 구현해보는 것을 목표로 합니다. 각 주차별로 제공된 이론 내용을 실제 코드로 구현하며, LLM 개발의 전체 파이프라인을 체계적으로 습득합니다.

## 평가 기준

- **구현 완성도 (40%)**: 요구된 기능이 올바르게 구현되었는가
- **이론적 이해 (30%)**: 구현背后的 수학적 원리를 이해하고 설명할 수 있는가
- **실험과 분석 (20%)**: 체계적인 실험 설계와 의미 있는 분석을 수행했는가
- **코드 품질 (10%)**: 코드 가독성, 효율성, 재사용성이 우수한가

---

## 9주차 과제: LLM 훈련 기초

### 과제 1: 토크나이저 구현과 비교 (30점)

**목표**: 다양한 토크나이저의 원리 이해와 구현

**기본 요구사항**:
1. **BPE 토크나이저从头 구현**
   - 문자 쌍 빈도 계산
   - 반복적 병합 알고리즘 구현
   - 어휘 구축과 인코딩/디코딩 함수

2. **WordPiece 토크나이저 구현**
   - 언어 모델 기반 병합 기준 구현
   - 손실 함수 계산
   - BPE와의 차이점 분석

3. **한국어 토크나이저 구현**
   - 형태소 분석 기반 토크나이징
   - 자모 단위 처리
   - 공백 처리와 어절 분리

4. **토크나이저 성능 비교**
   - 어휘 크기에 따른 성능 변화
   - OOV(Out-of-Vocabulary) 비율 분석
   - 인코딩/디코딩 속도 측정

**제출물**:
- `tokenizers/`: 토크나이저 구현 코드
- `tokenizer_comparison.ipynb`: 성능 비교 노트북
- `korean_tokenizer/`: 한국어 토크나이저 구현
- `analysis_report/`: 토크나이저 분석 보고서

**추가 도전 과제 (최대 5점 가산점)**:
- **SentencePiece 통합**: 구글의 SentencePiece 라이브러리와 통합
- **다국어 토크나이저**: 여러 언어를 동시에 처리하는 토크나이저
- **동적 토크나이저**: 입력에 따라 동적으로 토크나이징 전략 변경

### 과제 2: 언어 모델링 목적 함수 구현 (25점)

**목표**: 다양한 언어 모델링 목적 함수의 특성 이해와 구현

**기본 요구사항**:
1. **Causal Language Modeling (CLM) 구현**
   - 마스킹된 어텐션 구현
   - 교차 엔트로피 손실 계산
   - 자기 회귀 생성 함수

2. **Masked Language Modeling (MLM) 구현**
   - 랜덤 마스킹 전략 구현
   - 마스킹된 위치에서만 손실 계산
   - 다양한 마스킹 비율 실험

3. **Permutation Language Modeling (PLM) 구현**
   - 입력 순열 생성 알고리즘
   - 양방향 문맥 활용
   - XLNet 스타일의 순열 언어 모델링

4. **목적 함수 성능 비교**
   - 동일한 데이터셋에서의 성능 비교
   - 수렴 속도 분석
   - 생성 품질 평가

**제출물**:
- `language_models/`: 언어 모델 구현 코드
- `objective_comparison.ipynb`: 목적 함수 비교 노트북
- `generation_analysis/`: 생성 결과 분석
- `convergence_study/`: 수렴 특성 연구

**추가 도전 과제 (최대 5점 가산점)**:
- **Span Prediction**: 연속적인 토큰 범위 예측
- **Denoising Autoencoding**: 다양한 노이징 기법 적용
- **다중 목적 함수**: 여러 목적 함수를 결합한 훈련

### 과제 3: 분산 훈련 시뮬레이션 (20점)

**목표**: 대규모 모델 훈련의 분산 기법 이해와 시뮬레이션

**기본 요구사항**:
1. **데이터 병렬화 시뮬레이션**
   - 배치 데이터 분할 알고리즘
   - 그래디언트 수집과 평균화
   - 통신 오버헤드 분석

2. **모델 병렬화 시뮬레이션**
   - 파이프라인 병렬화 구현
   - 텐서 병렬화 구현
   - 메모리 사용량 최적화

3. **혼합 정밀도 훈련 시뮬레이션**
   - FP16 혼합 정밀도 훈련
   - 동적 손실 스케일링
   - 수치적 안정성 분석

4. **통신 최적화 시뮬레이션**
   - 그래디언트 압축 기법
   - 비동기 통신 구현
   - 통신-계산 중첩 효과 분석

**제출물**:
- `distributed_training/`: 분산 훈련 시뮬레이션 코드
- `memory_analysis/`: 메모리 사용량 분석
- `communication_study/`: 통신 최적화 연구
- `performance_report/`: 성능 분석 보고서

**추가 도전 과제 (최대 5점 가산점)**:
- **ZeRO (Zero Redundancy Optimizer)**: 3단계 최적화 시뮬레이션
- **MoE (Mixture of Experts)**: 전문가 혼합 모델 시뮬레이션
- **FSDP (Fully Sharded Data Parallelism)**: 완전 분할 데이터 병렬화

---

## 10주차 과제: 사전 훈련 전략

### 과제 1: 대규모 데이터 전처리 파이프라인 (30점)

**목표**: LLM 사전 훈련을 위한 대규모 데이터 처리 능력 습득

**기본 요구사항**:
1. **데이터 수집과 정제**
   - 웹 크롤링 데이터 수집
   - 중복 제거 알고리즘 구현
   - 품질 필터링 기법 적용

2. **다국어 데이터 처리**
   - 언어 식별 모듈 구현
   - 언어별 전처리 파이프라인
   - 다국어 데이터 통합

3. **개인정보 제거**
   - PII(개인 식별 정보) 탐지
   - 마스킹 vs 완전 제거 전략
   - 법적 규제 준수

4. **데이터 품질 평가**
   - 정량적 지표 계산
   - 정성적 분석 방법
   - 품질 보고서 생성

**제출물**:
- `data_pipeline/`: 데이터 전처리 파이프라인
- `multilingual_processing/`: 다국어 처리 모듈
- `privacy_protection/`: 개인정보 보호 모듈
- `quality_assessment/`: 데이터 품질 평가 도구

**추가 도전 과제 (최대 5점 가산점)**:
- **분산 데이터 처리**: 여러 머신에서의 데이터 처리
- **실시간 데이터 스트리밍**: 스트리밍 데이터 처리
- **자동 품질 평가**: 머신러닝 기반 품질 평가

### 과제 2: 사전 훈련 목적 함수 비교 (25점)

**목표**: 다양한 사전 훈련 목적 함수의 특성과 성능 비교

**기본 요구사항**:
1. **CLM vs MLM 비교 실험**
   - 동일한 데이터로 두 목적 함수 비교
   - 생성 품질 vs 이해 능력 평가
   - 훈련 안정성 분석

2. **다양한 마스킹 전략**
   - BERT 스타일 마스킹
   - SpanBERT 스타일 마스킹
   - Whole Word Masking

3. **사전 훈련 효율화**
   - 동적 배치 크기 조절
   - 긴 시퀀스 처리 기법
   - 메모리 효율적 훈련

4. **사전 훈련 성능 분석**
   - 훈련 곡선 시각화
   - 손실 함수 분석
   - 다운스트림 평가

**제출물**:
- `pretraining_objectives/`: 사전 훈련 목적 함수 구현
- `masking_strategies/`: 다양한 마스킹 전략
- `efficiency_optimization/`: 훈련 효율화 기법
- `performance_analysis/`: 성능 분석 결과

**추가 도전 과제 (최대 5점 가산점)**:
- **ElectRA 스타일**: 대체 토큰 감지 모델
- **T5 스타일**: 노이징 자동인코더
- **DeBERTa 스타일**: 분해된 어텐션

### 과제 3: 학습률 스케줄링과 최적화 (20점)

**목표**: 대규모 모델 훈련의 학습률 스케줄링과 최적화 기법 이해

**기본 요구사항**:
1. **다양한 학습률 스케줄러 구현**
   - 코사인 어닐링
   - 선형 감쇠
   - 순환 학습률

2. **최적화 기법 비교**
   - Adam vs AdamW vs Lion
   - 학습률 찾기 기법
   - 적응적 최적화

3. **하이퍼파라미터 튜닝**
   - 자동 하이퍼파라미터 탐색
   - 베이지안 최적화
   - 다목적 최적화

4. **훈련 안정성 분석**
   - 그래디언트 폭주/소실 분석
   - 손실 함수 안정성
   - 수렴 패턴 연구

**제출물**:
- `lr_schedulers/`: 학습률 스케줄러 구현
- `optimizers_comparison/`: 최적화 기법 비교
- `hyperparameter_tuning/`: 하이퍼파라미터 튜닝
- `stability_analysis/`: 훈련 안정성 분석

**추가 도전 과제 (최대 5점 가산점)**:
- **Lion 최적화**: 새로운 최적화 기법 구현
- **Sophia 최적화**: 이차 정보를 활용한 최적화
- **메타 학습**: 하이퍼파라미터 학습

---

## 11주차 과제: 미세조정 방법론

### 과제 1: 지도 미세조정(SFT) 구현 (30점)

**목표**: 지도 미세조정의 원리 이해와 실제 구현

**기본 요구사항**:
1. **지시 데이터 생성과 전처리**
   - 다양한 형식의 지시 데이터 생성
   - 데이터 포맷 변환
   - 품질 검증

2. **SFT 훈련 파이프라인 구현**
   - 데이터 로더 구현
   - 모델 미세조정
   - 평가와 체크포인팅

3. **다양한 지시 형식 지원**
   - Alpaca 형식
   - Vicuna 형식
   - ShareGPT 형식

4. **SFT 성능 평가**
   - 지시 따르기 능력 평가
   - 생성 품질 분석
   - 과적합 방지 기법

**제출물**:
- `sft_pipeline/`: SFT 훈련 파이프라인
- `instruction_formats/`: 다양한 지시 형식 처리
- `sft_model/`: 미세조정된 모델
- `evaluation_results/`: 성능 평가 결과

**추가 도전 과제 (최대 5점 가산점)**:
- **다중 작업 미세조정**: 여러 작업에 동시 미세조정
- **지시 데이터 증강**: 데이터 증강 기법 적용
- **지시 데이터 필터링**: 고품질 지시 데이터 선별

### 과제 2: RLHF 기본 구현 (35점)

**목표**: 인간 피드백을 통한 강화 학습의 원리 이해와 구현

**기본 요구사항**:
1. **보상 모델 훈련**
   - 선호도 데이터 생성
   - 보상 모델 구현
   - 보상 예측 평가

2. **PPO 알고리즘 구현**
   - 정책 그래디언트 계산
   - KL 발산 제약
   - 클리핑과 적응적 크리핑

3. **RLHF 파이프라인 구현**
   - 3단계 RLHF 과정 구현
   - 각 단계의 연결
   - 안정성 확보 기법

4. **RLHF 성능 평가**
   - 인간 선호도와 일치도 평가
   - 출력 품질 분석
   - 안전성 평가

**제출물**:
- `reward_model/`: 보상 모델 구현
- `ppo_algorithm/`: PPO 알고리즘 구현
- `rlhf_pipeline/`: RLHF 파이프라인
- `safety_evaluation/`: 안전성 평가

**추가 도전 과제 (최대 5점 가산점)**:
- **DPO (Direct Preference Optimization)**: 더 간단한 RLHF
- **KTO (Kahneman-Tversky Optimization)**: 행동 경제학 기반 최적화
- **Constitutional AI**: 헌법 기반 자기 수정

### 과제 3: 매개변수 효율적 미세조정(PEFT) 구현 (35점)

**목표**: 다양한 PEFT 방법의 원리 이해와 구현

**기본 요구사항**:
1. **LoRA 구현과 실험**
   - 저차원 적응 구현
   - 랭크와 알파 파라미터 실험
   - 성능-파라미터 트레이드오프 분석

2. **QLoRA 구현**
   - 양자화 기본 모델과 LoRA 결합
   - 4비트/8비트 양자화 실험
   - 메모리 사용량 분석

3. **어댑터 레이어 구현**
   - 다양한 어댑터 구조 실험
   - 순차 어댑터 vs 병렬 어댑터
   - 어댑터 퓨전 실험

4. **PEFT 방법 비교**
   - LoRA vs 어댑터 vs 프리픽스 튜닝
   - 성능-효율성 트레이드오프 분석
   - 다양한 작업에서의 성능 비교

**제출물**:
- `lora_implementation/`: LoRA 구현
- `qlora_implementation/`: QLoRA 구현
- `adapter_layers/`: 어댑터 레이어 구현
- `peft_comparison/`: PEFT 방법 비교

**추가 도전 과제 (최대 5점 가산점)**:
- **DoRA (Weight-Decomposed Low-Rank Adaptation)**: 가중치 분해 LoRA
- **LoRA+**: 여러 LoRA 변형 결합
- **Prompt Tuning**: 입력 공간에서의 미세조정

---

## Phase 3 종합 프로젝트

### 종합 프로젝트: LLM 미세조정 종합 실험 (100점)

**목표**: Phase 3에서 학습한 모든 미세조정 기법을 통합하여 최적의 미세조정 전략 탐색

**프로젝트 요구사항**:

1. **기본 미세조정 실험 (40점)**
   - 전체 미세조정 vs LoRA vs QLoRA
   - 다양한 데이터 크기에서의 성능 비교
   - 하이퍼파라미터 튜닝

2. **고급 미세조정 실험 (30점)**
   - SFT + PEFT 결합
   - RLHF + PEFT 결합
   - 다중 PEFT 방법 결합

3. **도메인 특화 미세조정 (20점)**
   - 특정 도메인(의료, 법률, 기술 등) 데이터로 미세조정
   - 도메인별 최적 전략 탐색
   - 일반 모델과의 성능 비교

4. **효율성과 성능 분석 (10점)**
   - 메모리 사용량 분석
   - 추론 속도 측정
   - 비용-성능 트레이드오프 분석

**제출물**:
- **코드**: 완전한 미세조정 실험 코드
- **보고서**: 기술 보고서와 실험 결과
- **발표**: 15분 발표 자료와 시연

---

## Phase 3 종합 평가

### 평가 방식
- **주별 과제 (60%)**: 각 주차별 과제 수행 평가
- **종합 프로젝트 (40%)**: 통합적인 미세조정 실험과 분석 능력 평가

### 피드백 방식
- **상세 코드 리뷰**: 각 과제에 대한 구체적인 피드백 제공
- **성능 벤치마크**: 다른 학생들의 결과와 비교
- **개선 제안**: 코드 개선과 성능 향상을 위한 구체적 제안

### 성공적인 과제 수행을 위한 조언

1. **이론과 실습의 연결**: 구현背后的 수학적 원리 이해
2. **점진적 구현**: 작은 단위로 나누어 구현하고 테스트
3. **실험 문서화**: 모든 실험 과정과 결과 상세히 기록
4. **성능 최적화**: 메모리와 계산 효율성 고려
5. **비교 분석**: 다양한 방법의 장단점 체계적 비교

## 추가 학습 자료

### 구현 참고 자료
- [Hugging Face PEFT Library](https://huggingface.co/docs/peft/)
- [TRL (Transformer Reinforcement Learning)](https://github.com/lvwerra/trl)
- [DeepSpeed](https://www.deepspeed.ai/)

### 데이터셋
- [Alpaca Dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html)
- [Dolly Dataset](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)
- [OpenAssistant Conversations](https://huggingface.co/datasets/OpenAssistant/oasst1)

### 성능 벤치마크
- [HELM (Holistic Evaluation of Language Models)](https://stanford-crfm.github.io/helm/latest/)
- [AlpacaEval](https://tatsu-lab.github.io/AlpacaEval/)
- [MT-Bench](https://arxiv.org/abs/2306.16634)

이 실습 과제들을 통해 학생들은 LLM의 핵심 기술인 트랜스포머 아키텍처, 사전 훈련, 미세조정 방법론에 대한 깊은 이해를 얻고, 실제 LLM 개발에 필요한 실용적 기술을 마스터하게 될 것입니다.