# Phase 1: 기초 다지기 - 실습 과제 모음

## 과제 개요

Phase 1의 실습 과제는 LLM 개발에 필요한 기초 지식과 기술을 체계적으로 습득하는 것을 목표로 합니다. 각 주차별로 제공된 이론 내용을 직접 구현하고 실험해보며, LLM 개발의 수학적, 프로그래밍적 기반을 다집니다.

## 평가 기준

- **코드 완성도 (40%)**: 요구된 기능이 올바르게 구현되었는가
- **이해도 (30%)**: 코드에 대한 설명과 결과 분석이 충분한가
- **창의성 (20%)**: 기본 요구사항 외 추가 실험이나 개선이 있는가
- **보고서 작성 (10%)**: 결과를 체계적으로 정리하고 제출했는가

---

## 1주차 과제: LLM 개요와 개발 환경 설정

### 과제 1: 개발 환경 설정 (10점)

**목표**: LLM 개발을 위한 기본 환경 구축

**요구사항**:
1. Python 가상 환경 생성 및 필수 라이브러리 설치
2. Jupyter Notebook/Lab 설정
3. GPU 환경 확인 (있는 경우)
4. 각 단계별 스크린샷과 설명 포함

**제출물**:
- `environment_setup.ipynb`: 환경 설정 과정을 담은 노트북
- `requirements.txt`: 설치된 라이브러리 목록
- 간단한 환경 설정 보고서 (1페이지 이내)

**추가 도전 과제**:
- Docker를 이용한 재현 가능한 개발 환경 구축
- Google Colab과 로컬 환경의 비교 분석

### 과제 2: LLM API 탐색 (15점)

**목표**: 다양한 LLM API 사용법 익히기

**요구사항**:
1. Hugging Face 모델 허브에서 3개 이상의 다른 모델 탐색
2. 각 모델의 특징과 사용법 정리
3. 텍스트 생성, 감성 분석, 질문 답변 태스크 수행
4. 모델별 성능과 특징 비교

**제출물**:
- `llm_api_exploration.ipynb`: API 탐색 과정을 담은 노트북
- `model_comparison.md`: 모델별 특징 비교표
- 생성된 텍스트 예시와 분석

**추가 도전 과제**:
- OpenAI API를 이용한 GPT 모델 실험
- 프롬프트 엔지니어링을 통한 출력 품질 향상

### 과제 3: LLM 역사 조사 (5점)

**목표**: LLM 발전 과정에 대한 이해

**요구사항**:
1. GPT 시리즈의 발전 과정 조사
2. 각 버전의 주요 특징과 성능 향상 정리
3. 다른 주요 LLM 계열(BERT, LLaMA 등)의 특징 비교
4. 시각적 타임라인 제작

**제출물**:
- `llm_history.pdf`: LLM 발전 과정을 정리한 보고서
- 시각적 자료 (타임라인, 비교표 등)

---

## 2주차 과제: 수학적 기초

### 과제 1: 선형대수 구현 (20점)

**목표**: NumPy를 이용한 선형대수 연산 구현

**요구사항**:
1. 3x3 행렬의 고유값 분해와 특이값 분해 구현
2. SVD를 이용한 이미지 압축 시뮬레이션
3. 단어 임베딩 벡터 간의 코사인 유사도 계산
4. 각 연산의 수학적 원리 설명

**제출물**:
- `linear_algebra.ipynb`: 선형대수 연산을 담은 노트북
- `image_compression/`: SVD 이미지 압축 결과
- `word_embeddings/`: 단어 임베딩 유사도 계산 결과

**추가 도전 과제**:
- PCA 처음부터 구현
- 고유값 분해와 SVD의 계산 복잡도 비교

### 과제 2: 미적분학적 개념 구현 (20점)

**목표**: 미적분학적 개념의 코드 구현

**요구사항**:
1. 다양한 활성화 함수(sigmoid, tanh, ReLU)의 도함수 구현
2. 2차원 함수에서의 경사 하강법 시각화
3. 연쇄 법칙을 이용한 간단한 신경망의 역전파 구현
4. 수치적 도함수와 해석적 도함수의 비교

**제출물**:
- `calculus_implementation.ipynb`: 미적분학적 개념 구현 노트북
- `gradient_descent_visualization/`: 경사 하강법 시각화 결과
- `backprop_implementation/`: 역전파 구현 코드

**추가 도전 과제**:
- 고차원 함수에서의 경사 하강법 구현
- 다양한 최적화 알고리즘(SGD, Momentum, Adam) 비교

### 과제 3: 확률과 통계 구현 (10점)

**목표**: 확률과 통계 개념의 코드 구현

**요구사항**:
1. 다양한 확률 분포의 시각화와 특성 분석
2. 베이즈 정리를 이용한 스팸 필터 간단 구현
3. 최대 가능도 추정을 이용한 정규 분포 파라미터 추정
4. 중심 극한 정리 시뮬레이션

**제출물**:
- `probability_statistics.ipynb`: 확률과 통계 구현 노트북
- `spam_filter/`: 스팸 필터 구현 코드
- `parameter_estimation/`: 파라미터 추정 결과

**추가 도전 과제**:
- 마르코프 체인 몬테카를로(MCMC) 기초 구현
- 베이즈 통계를 이용한 간단한 추론 시스템

---

## 3주차 과제: 머신러닝 기초

### 과제 1: 회귀 모델 비교 (15점)

**목표**: 다양한 회귀 모델의 성능 비교

**요구사항**:
1. 보스턴 주택 가격 데이터셋에 대한 다양한 회귀 모델 비교
2. 다항 회귀에서의 최적 차수 선택
3. 정규화 강도에 따른 성능 변화 분석
4. 교차 검증을 통한 모델 평가

**제출물**:
- `regression_comparison.ipynb`: 회귀 모델 비교 노트북
- `model_evaluation/`: 모델 평가 결과
- `hyperparameter_tuning/`: 하이퍼파라미터 튜닝 과정

**추가 도전 과제**:
- 앙상블 방법(Bagging, Boosting) 적용
- 특성 중요도 분석 및 시각화

### 과제 2: 분류 모델 비교 (15점)

**목표**: 다양한 분류 알고리즘의 성능 비교

**요구사항**:
1. 와인 데이터셋에 대한 다양한 분류 알고리즘 비교
2. 특성 스케일링이 모델 성능에 미치는 영향 분석
3. 혼동 행렬을 통한 분류 결과 상세 분석
4. ROC 곡선과 AUC 계산

**제출물**:
- `classification_comparison.ipynb`: 분류 모델 비교 노트북
- `confusion_matrices/`: 혼동 행렬 시각화
- `roc_curves/`: ROC 곡선 시각화

**추가 도전 과제**:
- 불균형 데이터 처리 기법 적용
- 다중 클래스 분류에서의 성능 평가 지표 비교

### 과제 3: 비지도 학습 구현 (10점)

**목표**: 비지도 학습 알고리즘 구현

**요구사항**:
1. K-평균 클러스터링에서 최적 클러스터 수 찾기
2. PCA를 이용한 차원 축소 및 시각화
3. t-SNE와 PCA의 차이점 비교 분석
4. 군집화 결과 평가

**제출물**:
- `unsupervised_learning.ipynb`: 비지도 학습 구현 노트북
- `clustering_results/`: 클러스터링 결과 시각화
- `dimensionality_reduction/`: 차원 축소 결과

**추가 도전 과제**:
- DBSCAN과 같은 밀도 기반 클러스터링 구현
- 계층적 클러스터링과 덴드로그램 시각화

---

## 4주차 과제: 딥러닝 기초

### 과제 1: 신경망 구조 실험 (20점)

**목표**: 신경망 구조에 따른 성능 변화 분석

**요구사항**:
1. 다양한 은닉층 크기에 따른 성능 비교
2. 깊이(층 수)에 따른 성능 변화 분석
3. 과적합과 과소적합 사례 분석
4. 학습 곡선을 통한 모델 진단

**제출물**:
- `neural_network_architecture.ipynb`: 신경망 구조 실험 노트북
- `learning_curves/`: 학습 곡선 시각화
- `overfitting_analysis/`: 과적합 분석 결과

**추가 도전 과제**:
- 드롭아웃과 배치 정규화 효과 비교
- 잔차 연결(Residual Connections) 구현

### 과제 2: 활성화 함수 비교 (15점)

**목표**: 다양한 활성화 함수의 특성 비교

**요구사항**:
1. 다양한 활성화 함수를 사용한 신경망 성능 비교
2. 그래디언트 소실 문제 시뮬레이션
3. Xavier/He 초기화와 활성화 함수의 관계 분석
4. 활성화 함수별 수렴 속도 비교

**제출물**:
- `activation_functions.ipynb`: 활성화 함수 비교 노트북
- `gradient_analysis/`: 그래디언트 분석 결과
- `initialization_methods/`: 초기화 방법 비교

**추가 도전 과제**:
- 사용자 정의 활성화 함수 설계 및 실험
- 활성화 함수의 미분 가능성 분석

### 과제 3: 최적화 알고리즘 비교 (15점)

**목표**: 다양한 최적화 알고리즘의 성능 비교

**요구사항**:
1. 다양한 옵티마이저(SGD, Adam, RMSprop) 성능 비교
2. 학습률 스케줄링 효과 분석
3. 배치 크기에 따른 훈련 속도와 성능 비교
4. 손실 함수의 지형 시각화

**제출물**:
- `optimization_algorithms.ipynb`: 최적화 알고리즘 비교 노트북
- `learning_rate_scheduling/`: 학습률 스케줄링 결과
- `batch_size_analysis/`: 배치 크기 분석 결과

**추가 도전 과제**:
- 2차 최적화 알고리즘(L-BFGS 등) 구현
- 적응적 학습률 방법의 수학적 원리 분석

---

## Phase 1 종합 프로젝트 (30점)

### 프로젝트: 간단한 텍스트 분류기 구현

**목표**: Phase 1에서 학습한 모든 개념을 통합하여 간단한 텍스트 분류기 구현

**요구사항**:
1. 데이터 수집 및 전처리
2. 텍스트 특성 추출 (TF-IDF, Word2Vec 등)
3. 다양한 머신러닝/딥러닝 모델 구현 및 비교
4. 모델 평가와 성능 분석
5. 결과 시각화와 보고서 작성

**제출물**:
- `text_classifier/`: 전체 프로젝트 코드
- `model_comparison/`: 모델별 성능 비교 결과
- `final_report.pdf`: 프로젝트 보고서 (최소 5페이지)
- `presentation slides/`: 발표 자료

**평가 기준**:
- 코드의 완성도와 정확성 (40%)
- 다양한 모델의 체계적 비교 (30%)
- 결과 분석의 깊이 (20%)
- 보고서와 발표 자료의 질 (10%)

---

## 제출 가이드라인

### 제출 형식
- 모든 코드는 Jupyter Notebook 형식으로 제출
- 코드 실행 결과와 시각화 자료 포함
- 각 과제별로 별도의 폴더 구조 유지
- README.md 파일에 과제 내용과 실행 방법 명시

### 제출 마감
- 1주차 과제: 2주차 수업 시작 전
- 2주차 과제: 3주차 수업 시작 전
- 3주차 과제: 4주차 수업 시작 전
- 4주차 과제: 5주차 수업 시작 전
- 종합 프로젝트: 5주차 수업 시간 발표

### 협력 정책
- 개별 과제 수행 원칙
- 코드 참조 시 반드시 출처 명시
- 토의와 아이디어 공유는 장려
- 직접적인 코드 복사는 금지

### 평가 피드백
- 제출 후 1주일 내 상세 피드백 제공
- 코드 리뷰와 개선 제안
- 우수 과제는 클래스 전체 공유
- 재제출 기회 제공 (점수 상한 80%)

## 추가 학습 자료

### 온라인 플랫폼
- [Kaggle](https://www.kaggle.com/): 데이터셋과 경진 대회
- [Google Colab](https://colab.research.google.com/): 무료 GPU 환경
- [GitHub](https://github.com/): 코드 버전 관리와 협업

### 추천 튜토리얼
- [PyTorch Official Tutorials](https://pytorch.org/tutorials/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Machine Learning Mastery](https://machinelearningmastery.com/)

### 참고 서적
- "Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow"
- "Python for Data Analysis"
- "Deep Learning with PyTorch"