{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn 첫걸음\n",
    "\n",
    "이 노트북은 scikit-learn과의 첫 만남을 위한 실습입니다. 머신러닝의 기본 개념과 scikit-learn API의 일관성을 배우게 됩니다.\n",
    "\n",
    "## 학습 목표\n",
    "- scikit-learn 설치 확인\n",
    "- 기본 데이터셋 탐색\n",
    "- 첫 번째 머신러닝 모델 훈련\n",
    "- scikit-learn API 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. scikit-learn 설치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 버전 확인\n",
    "print(f\"scikit-learn 버전: {sklearn.__version__}\")\n",
    "print(f\"NumPy 버전: {np.__version__}\")\n",
    "print(f\"pandas 버전: {pd.__version__}\")\n",
    "\n",
    "# scikit-learn 주요 모듈 임포트\n",
    "from sklearn import datasets, model_selection, preprocessing, metrics\n",
    "print(\"✅ 모든 모듈이 성공적으로 임포트되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 첫 번째 데이터셋 탐색: Iris 데이터셋\n",
    "\n",
    "Iris 데이터셋은 머신러닝에서 가장 유명한 데이터셋 중 하나입니다. 세 가지 종류의 붓꽃에 대한 꽃잎과 꽃받침 측정값을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris 데이터셋 로드\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 데이터 정보 확인\n",
    "print(f\"데이터셋 특성: {iris.feature_names}\")\n",
    "print(f\"타겟 클래스: {iris.target_names}\")\n",
    "print(f\"데이터 형태: {iris.data.shape}\")\n",
    "print(f\"타겟 형태: {iris.target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas DataFrame으로 변환하여 탐색\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target\n",
    "iris_df['species_name'] = iris_df['species'].map({\n",
    "    0: 'setosa', \n",
    "    1: 'versicolor', \n",
    "    2: 'virginica'\n",
    "})\n",
    "\n",
    "# 처음 5개 샘플 확인\n",
    "print(\"처음 5개 샘플:\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 통계 정보\n",
    "print(\"데이터셋 통계:\")\n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 분포 확인\n",
    "print(\"클래스별 샘플 수:\")\n",
    "iris_df['species_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 꽃잎 길이 vs 꽃잎 너비\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(\n",
    "    data=iris_df, \n",
    "    x='petal length (cm)', \n",
    "    y='petal width (cm)', \n",
    "    hue='species_name', \n",
    "    style='species_name', \n",
    "    s=100\n",
    ")\n",
    "plt.title('꽃잎 길이 vs 꽃잎 너비')\n",
    "\n",
    "# 꽃받침 길이 vs 꽃받침 너비\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(\n",
    "    data=iris_df, \n",
    "    x='sepal length (cm)', \n",
    "    y='sepal width (cm)', \n",
    "    hue='species_name', \n",
    "    style='species_name', \n",
    "    s=100\n",
    ")\n",
    "plt.title('꽃받침 길이 vs 꽃받침 너비')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 첫 번째 머신러닝 모델: K-최근접 이웃 (K-Nearest Neighbors)\n",
    "\n",
    "이제 간단한 분류 모델을 훈련해 보겠습니다. K-최근접 이웃은 가장 직관적인 분류 알고리즘 중 하나입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현성을 위한 랜덤 시드 설정\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# 특성과 타겟 분리\n",
    "X = iris.data  # 특성\n",
    "y = iris.target  # 타겟\n",
    "\n",
    "print(f\"특성 형태: {X.shape}\")\n",
    "print(f\"타겟 형태: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (훈련 세트와 테스트 세트)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,  # 20%를 테스트용으로 사용\n",
    "    random_state=RANDOM_STATE,  # 재현성을 위한 랜덤 시드\n",
    "    stratify=y  # 클래스 비율 유지\n",
    ")\n",
    "\n",
    "print(f\"훈련 세트 크기: {X_train.shape[0]}\")\n",
    "print(f\"테스트 세트 크기: {X_test.shape[0]}\")\n",
    "print(f\"훈련 세트 클래스 분포: {np.bincount(y_train)}\")\n",
    "print(f\"테스트 세트 클래스 분포: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-최근접 이웃 분류기 생성 및 훈련\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 모델 생성 (k=3)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# 모델 훈련\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ 모델 훈련 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 수행\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"모델 정확도: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상세 성능 평가\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"분류 보고서:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=iris.target_names,\n",
    "    yticklabels=iris.target_names\n",
    ")\n",
    "plt.xlabel('예측된 클래스')\n",
    "plt.ylabel('실제 클래스')\n",
    "plt.title('혼동 행렬')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 새로운 데이터에 대한 예측\n",
    "\n",
    "이제 훈련된 모델을 사용하여 새로운 꽃 샘플을 분류해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 꽃 샘플 (꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비)\n",
    "new_flowers = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],  # setosa처럼 보임\n",
    "    [6.7, 3.0, 5.2, 2.3],  # virginica처럼 보임\n",
    "    [5.9, 3.0, 4.2, 1.5]   # versicolor처럼 보임\n",
    "])\n",
    "\n",
    "# 예측 수행\n",
    "predictions = knn.predict(new_flowers)\n",
    "predicted_species = [iris.target_names[p] for p in predictions]\n",
    "\n",
    "print(\"새로운 꽃에 대한 예측:\")\n",
    "for i, (flower, species) in enumerate(zip(new_flowers, predicted_species)):\n",
    "    print(f\"꽃 {i+1} {flower} -> {species}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. scikit-learn API 일관성 탐색\n",
    "\n",
    "scikit-learn의 강점은 모든 알고리즘이 동일한 API를 따른다는 것입니다. 다른 분류 알고리즘을 사용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 분류 알고리즘 시도\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 모델 초기화\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'SVM': SVC(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# 모든 모델 훈련 및 평가\n",
    "print(\"모델 성능 비교:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # 동일한 API: fit()으로 훈련\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 동일한 API: predict()로 예측\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 성능 평가\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name}: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모범 사례: 데이터 전처리와 모델 파이프라인\n",
    "\n",
    "실제 머신러닝 프로젝트에서는 데이터 전처리가 중요합니다. 스케일링이 모델 성능에 미치는 영향을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 스케일러 생성 및 훈련 데이터에 맞춤\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터는 동일한 스케일러로 변환\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"스케일링 전 데이터 통계:\")\n",
    "print(f\"평균: {X_train.mean(axis=0)}\")\n",
    "print(f\"표준편차: {X_train.std(axis=0)}\")\n",
    "\n",
    "print(\"\\n스케일링 후 데이터 통계:\")\n",
    "print(f\"평균: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"표준편차: {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링된 데이터로 모델 훈련 및 평가\n",
    "print(\"스케일링된 데이터로 모델 성능 비교:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # 스케일링된 데이터로 훈련\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 스케일링된 테스트 데이터로 예측\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # 성능 평가\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name}: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 요약 및 다음 단계\n",
    "\n",
    "이 노트북에서는 다음을 배웠습니다:\n",
    "\n",
    "1. ✅ scikit-learn 설치 및 환경 설정\n",
    "2. ✅ 기본 데이터셋 탐색 및 시각화\n",
    "3. ✅ 데이터 분할 (훈련/테스트)\n",
    "4. ✅ 첫 번째 머신러닝 모델 훈련\n",
    "5. ✅ 모델 성능 평가\n",
    "6. ✅ scikit-learn API의 일관성\n",
    "7. ✅ 데이터 전처리의 중요성\n",
    "\n",
    "### 다음 단계:\n",
    "- 모듈 2: 데이터 전처리 및 특성 공학 심화\n",
    "- 다양한 전처리 기법 학습\n",
    "- 더 복잡한 데이터셋으로 연습\n",
    "\n",
    "### 추가 연습:\n",
    "- 다른 k 값으로 KNN 모델 훈련 및 성능 비교\n",
    "- 다른 scikit-learn 데이터셋으로 실험\n",
    "- 교차 검증에 대해 알아보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}